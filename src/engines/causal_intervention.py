#!/usr/bin/env python3
"""
Causal Intervention Analysis Module
Handles 'what-if' scenario analysis using do-calculus.
"""

import pandas as pd
import numpy as np
import gradio as gr
from causalnex.structure.notears import from_pandas
from causalnex.network import BayesianNetwork
from causalnex.inference import InferenceEngine
from causalnex.discretiser import Discretiser

from ..core import dashboard_config
from .causal_network_utils import has_cycles, resolve_cycles
from .causal_discretization import create_ultra_robust_split_points

def perform_causal_intervention_analysis(target_var, intervention_var, intervention_value, progress=gr.Progress()):
    """Perform causal intervention analysis (do-calculus)"""

    try:
        progress(0.1, desc="ğŸ”¬ Preparing intervention analysis...")

        if dashboard_config.current_data is None:
            return "âŒ No data loaded", "Please upload data first"

        # Get numeric data
        df_numeric = dashboard_config.current_data.select_dtypes(include=[np.number])
        if df_numeric.empty:
            return "âŒ No numeric data found", "Please ensure your data contains numeric variables"

        if target_var not in df_numeric.columns or intervention_var not in df_numeric.columns:
            return "âŒ Variables not found", "Selected variables not found in data"

        progress(0.4, desc="ğŸ” Validating data quality...")

        # Check for sufficient variation in key variables
        target_variation = df_numeric[target_var].std()
        intervention_variation = df_numeric[intervention_var].std()

        if target_variation < 1e-10:
            return f"""
            âŒ Intervention analysis failed: Insufficient variation in target variable

            **Problem:** The target variable '{target_var}' has no variation (std = {target_variation:.2e})

            **Solutions:**
            â€¢ Choose a different target variable with more diverse values
            â€¢ Check if the data contains only constant values
            â€¢ Ensure the variable represents a meaningful outcome
            """, "Target variable has insufficient variation"

        if intervention_variation < 1e-10:
            return f"""
            âŒ Intervention analysis failed: Insufficient variation in intervention variable

            **Problem:** The intervention variable '{intervention_var}' has no variation (std = {intervention_variation:.2e})

            **Solutions:**
            â€¢ Choose a different intervention variable with more diverse values
            â€¢ Check if the data contains only constant values
            â€¢ Ensure the variable can be meaningfully changed
            """, "Intervention variable has insufficient variation"

        progress(0.3, desc="ğŸ—ï¸ Building causal structure...")

        # Build causal structure using NOTEARS with cycle detection
        try:
            sm = from_pandas(df_numeric, max_iter=100, h_tol=1e-8, w_threshold=0.3)

            # Check for cycles in the structure
            if has_cycles(sm):
                print("âš ï¸ Detected cycles in causal structure, applying cycle resolution...")
                sm = resolve_cycles(sm, df_numeric)

        except Exception as e:
            if "not acyclic" in str(e) or "cycle" in str(e).lower():
                return f"""
                âŒ Intervention analysis failed: Cyclic causal structure detected

                **Problem:** The causal discovery algorithm found bidirectional relationships that create cycles.

                **Detected Issue:** {str(e)}

                **Solutions:**
                â€¢ Try with fewer variables (select 5-10 most important ones)
                â€¢ Increase the w_threshold parameter to filter weak relationships
                â€¢ Use domain knowledge to remove variables that shouldn't be causally related
                â€¢ Consider that some relationships might be correlational rather than causal

                **Technical Note:** Bayesian Networks require acyclic structures (DAGs).
                Cycles often indicate confounding variables or bidirectional relationships
                that need to be resolved through domain expertise.
                """, f"Cyclic structure error: {str(e)}"
            else:
                raise e

        progress(0.5, desc="ğŸ§  Creating Bayesian Network...")

        # Create split points for each column with extensive validation
        split_points = {}
        failed_columns = []

        for col in df_numeric.columns:
            try:
                # Get column data and check quality
                col_data = df_numeric[col]
                unique_count = col_data.nunique()

                print(f"ğŸ“Š Processing {col}: {len(col_data)} values, {unique_count} unique")

                if unique_count < 2:
                    print(f"âš ï¸ Column {col} has insufficient variation ({unique_count} unique values)")
                    failed_columns.append(col)
                    continue

                splits = create_ultra_robust_split_points(col_data)

                # Validate splits
                if len(splits) != 2:
                    raise ValueError(f"Expected 2 split points, got {len(splits)}")

                if splits[1] <= splits[0]:
                    raise ValueError(f"Split points not monotonic: {splits}")

                if not all(np.isfinite(splits)):
                    raise ValueError(f"Split points contain invalid values: {splits}")

                split_points[col] = splits
                print(f"âœ… Created valid split points for {col}: {splits}")

            except Exception as e:
                print(f"âŒ Failed to create split points for {col}: {e}")
                failed_columns.append(col)

        # Remove failed columns from analysis
        if failed_columns:
            print(f"âš ï¸ Removing {len(failed_columns)} columns with discretization issues: {failed_columns}")
            df_numeric = df_numeric.drop(columns=failed_columns)

            # Check if we still have enough variables
            if len(df_numeric.columns) < 2:
                return f"""
                âŒ Intervention analysis failed: Insufficient valid variables

                **Problem:** After removing columns with discretization issues, only {len(df_numeric.columns)} variables remain.

                **Failed columns:** {', '.join(failed_columns)}

                **Solutions:**
                â€¢ Use a dataset with more diverse numeric variables
                â€¢ Check data quality (remove constant or near-constant columns)
                â€¢ Ensure variables have at least 10+ unique values
                â€¢ Try with different variable combinations
                """, "Insufficient variables for analysis"

            # Check if target/intervention variables are still available
            if target_var not in df_numeric.columns:
                return f"""
                âŒ Intervention analysis failed: Target variable removed

                **Problem:** Target variable '{target_var}' was removed due to discretization issues.

                **Solutions:**
                â€¢ Choose a different target variable with more variation
                â€¢ Check if '{target_var}' has sufficient unique values
                â€¢ Ensure the variable represents a meaningful outcome
                """, "Target variable unavailable"

            if intervention_var not in df_numeric.columns:
                return f"""
                âŒ Intervention analysis failed: Intervention variable removed

                **Problem:** Intervention variable '{intervention_var}' was removed due to discretization issues.

                **Solutions:**
                â€¢ Choose a different intervention variable with more variation
                â€¢ Check if '{intervention_var}' has sufficient unique values
                â€¢ Ensure the variable can be meaningfully changed
                """, "Intervention variable unavailable"

        # Final validation and cleanup of all split points before creating discretizer
        print(f"ğŸ” Final validation of split points for {len(split_points)} variables...")
        cleaned_split_points = {}

        for col, splits in split_points.items():
            # Round to avoid floating point precision issues
            rounded_splits = [round(float(s), 10) for s in splits]

            # Ensure strict monotonic increasing with minimum separation
            if len(rounded_splits) != 2:
                print(f"âŒ Invalid number of splits for {col}: {len(rounded_splits)}")
                continue

            if not all(np.isfinite(rounded_splits)):
                print(f"âŒ Non-finite splits for {col}: {rounded_splits}")
                continue

            # Ensure monotonic with minimum separation
            min_separation = 1e-8
            if rounded_splits[1] <= rounded_splits[0]:
                print(f"âš ï¸ Non-monotonic splits for {col}: {rounded_splits}, fixing...")
                rounded_splits[1] = rounded_splits[0] + min_separation
            elif rounded_splits[1] - rounded_splits[0] < min_separation:
                print(f"âš ï¸ Insufficient separation for {col}: {rounded_splits}, fixing...")
                rounded_splits[1] = rounded_splits[0] + min_separation

            cleaned_split_points[col] = rounded_splits
            print(f"âœ… Validated splits for {col}: {rounded_splits} (diff: {rounded_splits[1] - rounded_splits[0]:.2e})")

        # Update split_points with cleaned version
        split_points = cleaned_split_points

        # Skip CausalNex discretizer entirely - use manual discretization only
        print(f"ğŸ—ï¸ Using manual discretization (bypassing CausalNex discretizer issues)...")

        # Manual discretization using pandas cut - this always works
        df_discretised = df_numeric.copy()
        discretization_info = {}

        for col in df_numeric.columns:
            try:
                # Calculate quantile thresholds
                q33 = df_numeric[col].quantile(0.33)
                q67 = df_numeric[col].quantile(0.67)

                # Store thresholds for intervention value discretization
                discretization_info[col] = {'q33': q33, 'q67': q67}

                # Apply discretization
                df_discretised[col] = pd.cut(
                    df_numeric[col],
                    bins=[-np.inf, q33, q67, np.inf],
                    labels=['low', 'medium', 'high']
                )

                print(f"âœ… Discretized {col}: low â‰¤ {q33:.3f}, medium â‰¤ {q67:.3f}, high > {q67:.3f}")

            except Exception as e:
                return f"""
                âŒ Intervention analysis failed: Manual discretization error

                **Problem:** Could not discretize variable '{col}': {str(e)}

                **Solutions:**
                â€¢ Check that '{col}' contains valid numeric values
                â€¢ Ensure the variable has sufficient variation
                â€¢ Remove any infinite or extremely large values
                """, f"Manual discretization error for {col}: {str(e)}"

        print(f"âœ… Manual discretization completed successfully for {len(df_numeric.columns)} variables")

        # Apply discretization with error handling
        try:
            print(f"ğŸ”„ Attempting to discretize data with shape: {df_numeric.shape}")
            print(f"ğŸ“Š Data types: {df_numeric.dtypes.to_dict()}")
            print(f"ğŸ“Š Data sample:\n{df_numeric.head()}")

            # Try to fit and transform in separate steps for better error handling
            discretiser = discretiser.fit(df_numeric)
            df_discretised = discretiser.transform(df_numeric)
            print(f"âœ… Successfully discretized data: {df_discretised.shape}")

        except Exception as e:
            print(f"âŒ Discretization failed with error: {str(e)}")

            # Try alternative approach: manual discretization
            try:
                print("ğŸ”„ Trying manual discretization as fallback...")
                df_discretised = df_numeric.copy()

                for col in df_numeric.columns:
                    # Simple quantile-based discretization
                    q33 = df_numeric[col].quantile(0.33)
                    q67 = df_numeric[col].quantile(0.67)

                    df_discretised[col] = pd.cut(
                        df_numeric[col],
                        bins=[-np.inf, q33, q67, np.inf],
                        labels=['low', 'medium', 'high']
                    )

                print(f"âœ… Manual discretization successful: {df_discretised.shape}")
                print(f"ğŸ“Š Discretized sample:\n{df_discretised.head()}")

            except Exception as e2:
                return f"""
                âŒ Intervention analysis failed: Data transformation error

                **Problem:** Both automatic and manual discretization failed

                **Primary error:** {str(e)}
                **Fallback error:** {str(e2)}

                **Solutions:**
                â€¢ Check that your data contains valid numeric values
                â€¢ Remove any infinite or extremely large values
                â€¢ Ensure variables have reasonable ranges
                â€¢ Try with a smaller subset of variables
                â€¢ Consider using different variable combinations

                **Data info:**
                â€¢ Target variable range: {df_numeric[target_var].min():.3f} to {df_numeric[target_var].max():.3f}
                â€¢ Intervention variable range: {df_numeric[intervention_var].min():.3f} to {df_numeric[intervention_var].max():.3f}
                """, f"Data transformation error: {str(e)}"

        # Create Bayesian Network
        bn = BayesianNetwork(sm)
        bn = bn.fit_node_states(df_discretised)
        bn = bn.fit_cpds(df_discretised, method="BayesianEstimator", bayes_prior="K2")

        progress(0.7, desc="ğŸ¯ Performing intervention...")

        # Create inference engine
        ie = InferenceEngine(bn)

        # Validate and discretize intervention value
        intervention_min = df_numeric[intervention_var].min()
        intervention_max = df_numeric[intervention_var].max()

        # Check if intervention value is within reasonable range
        if intervention_value < intervention_min * 0.5 or intervention_value > intervention_max * 2.0:
            return f"""
            âŒ Intervention analysis failed: Intervention value out of range

            **Problem:** Intervention value {intervention_value} is outside reasonable range

            **Data range for {intervention_var}:**
            â€¢ Minimum: {intervention_min:.3f}
            â€¢ Maximum: {intervention_max:.3f}
            â€¢ Suggested range: {intervention_min:.3f} to {intervention_max:.3f}

            **Solutions:**
            â€¢ Use an intervention value within the data range
            â€¢ Try values between {intervention_min:.1f} and {intervention_max:.1f}
            â€¢ Consider the practical meaning of your intervention
            """, "Intervention value out of range"

        try:
            # Use the same manual discretization approach for intervention value
            q33 = df_numeric[intervention_var].quantile(0.33)
            q67 = df_numeric[intervention_var].quantile(0.67)

            if intervention_value <= q33:
                intervention_state = 'low'
            elif intervention_value <= q67:
                intervention_state = 'medium'
            else:
                intervention_state = 'high'

            print(f"âœ… Intervention value {intervention_value} discretized to state: {intervention_state}")
            print(f"ğŸ“Š Discretization thresholds: low â‰¤ {q33:.3f}, medium â‰¤ {q67:.3f}, high > {q67:.3f}")

        except Exception as e:
            return f"""
            âŒ Intervention analysis failed: Could not discretize intervention value

            **Problem:** Error discretizing intervention value {intervention_value}: {str(e)}

            **Solutions:**
            â€¢ Try an intervention value closer to the data mean: {df_numeric[intervention_var].mean():.3f}
            â€¢ Ensure the value is a valid number
            â€¢ Check that the value makes sense for your variable
            """, f"Intervention discretization error: {str(e)}"

        # Perform intervention (do-calculus)
        intervention_query = ie.do_intervention(
            {intervention_var: intervention_state},
            {target_var: list(df_discretised[target_var].unique())}
        )

        progress(0.9, desc="ğŸ“Š Generating results...")

        # Calculate baseline probabilities (without intervention)
        baseline_query = ie.query({target_var: list(df_discretised[target_var].unique())})

        # Create results summary
        results_html = f"""
        <div style="background: white; padding: 20px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1);">
            <h3>ğŸ¯ Causal Intervention Analysis</h3>

            <div style="background: #f8f9fa; padding: 15px; border-radius: 8px; margin: 15px 0;">
                <h4>ğŸ“‹ Analysis Setup</h4>
                <p><strong>Target Variable:</strong> {target_var}</p>
                <p><strong>Intervention Variable:</strong> {intervention_var}</p>
                <p><strong>Intervention Value:</strong> {intervention_value} â†’ {intervention_state}</p>
            </div>

            <div style="background: #e3f2fd; padding: 15px; border-radius: 8px; margin: 15px 0;">
                <h4>ğŸ“Š Probability Distributions</h4>

                <h5>ğŸ”µ Baseline (Observational)</h5>
                <div style="font-family: monospace; background: white; padding: 10px; border-radius: 4px;">
        """

        for state, prob in baseline_query.items():
            results_html += f"P({target_var} = {state}) = {prob:.4f}<br>"

        results_html += """
                </div>

                <h5>ğŸ”´ After Intervention</h5>
                <div style="font-family: monospace; background: white; padding: 10px; border-radius: 4px;">
        """

        for state, prob in intervention_query.items():
            results_html += f"P({target_var} = {state} | do({intervention_var} = {intervention_state})) = {prob:.4f}<br>"

        results_html += """
                </div>
            </div>

            <div style="background: #f3e5f5; padding: 15px; border-radius: 8px; margin: 15px 0;">
                <h4>ğŸ“ˆ Causal Effect Analysis</h4>
        """

        # Calculate causal effects
        for state in baseline_query.keys():
            baseline_prob = baseline_query[state]
            intervention_prob = intervention_query[state]
            effect = intervention_prob - baseline_prob
            effect_pct = (effect / baseline_prob * 100) if baseline_prob > 0 else 0

            effect_color = "#4caf50" if effect > 0 else "#f44336" if effect < 0 else "#757575"
            results_html += f"""
                <p style="color: {effect_color};">
                    <strong>{target_var} = {state}:</strong>
                    {effect:+.4f} ({effect_pct:+.1f}% change)
                </p>
            """

        results_html += """
            </div>

            <div style="background: #fff3e0; padding: 15px; border-radius: 8px; margin: 15px 0;">
                <h4>ğŸ’¡ Interpretation</h4>
                <p>This analysis shows the <strong>causal effect</strong> of intervening on <strong>{intervention_var}</strong>
                and setting it to <strong>{intervention_value}</strong> on the probability distribution of <strong>{target_var}</strong>.</p>
                <p>The differences between baseline and intervention probabilities represent the <strong>true causal impact</strong>,
                not just correlation.</p>
            </div>
        </div>
        """.format(intervention_var=intervention_var, intervention_value=intervention_value, target_var=target_var)

        progress(1.0, desc="âœ… Intervention analysis complete!")

        return results_html, "âœ… Causal intervention analysis completed successfully!"

    except Exception as e:
        progress(1.0, desc="âŒ Analysis failed")

        # Provide specific error guidance
        error_details = str(e)
        if "monotonically increasing" in error_details:
            error_msg = """
            âŒ Intervention analysis failed: Data discretization issue

            **Problem:** The selected variables have insufficient variation for Bayesian Network analysis.

            **Solutions:**
            â€¢ Try different variables with more variation
            â€¢ Ensure your data has diverse values (not mostly the same)
            â€¢ Use variables with continuous distributions
            â€¢ Check that your intervention value is within the data range

            **Technical details:** """ + error_details
        elif "intervention" in error_details.lower():
            error_msg = f"""
            âŒ Intervention analysis failed: {error_details}

            **Suggestions:**
            â€¢ Check that the intervention value is reasonable for your data
            â€¢ Ensure both variables have sufficient data points
            â€¢ Try with different variable combinations
            """
        else:
            error_msg = f"""
            âŒ Intervention analysis failed: {error_details}

            **Common causes:**
            â€¢ Insufficient data (need at least 50+ rows)
            â€¢ Variables with little variation
            â€¢ Missing or invalid values
            â€¢ Causal structure too complex for the data size
            """

        return error_msg, error_msg
